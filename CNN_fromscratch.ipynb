{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Rescaling\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from skimage import color\n",
    "from matplotlib.pyplot import imshow\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# we get local data_path\n",
    "data_path = ''\n",
    "\n",
    "classes_index = 0\n",
    "label_list = []\n",
    "        \n",
    "class Dataset(object):\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        assert os.path.exists(self.data_path), 'Insert a valid path!'\n",
    "\n",
    "        # get class list\n",
    "        self.data_classes = os.listdir(self.data_path)\n",
    "\n",
    "        # init mapping dict\n",
    "        self.data_mapping = {}\n",
    "\n",
    "        # populate mapping dict\n",
    "        for c, c_name in enumerate(self.data_classes):\n",
    "            temp_path = os.path.join(self.data_path, c_name)\n",
    "            temp_images = os.listdir(temp_path)\n",
    "\n",
    "            for i in temp_images:\n",
    "                img_tmp = os.path.join(temp_path, i)\n",
    "\n",
    "                if img_tmp.lower().endswith(('.jpg', '.jpeg')):\n",
    "                    if c_name == 'distractor':\n",
    "                        self.data_mapping[img_tmp] = -1\n",
    "                    else:\n",
    "                        self.data_mapping[img_tmp] = c_name\n",
    "\n",
    "        print('Loaded {:d} from {:s} images'.format(len(self.data_mapping.keys()),\n",
    "                                                    self.data_path))\n",
    "        \n",
    "    def get_data_paths(self):\n",
    "        # returns a list of imgpaths and related classes\n",
    "        images = []\n",
    "        classes = []\n",
    "        for img_path in self.data_mapping.keys():\n",
    "            if img_path.lower().endswith(('.jpg', '.jpeg')):\n",
    "                images.append(img_path)\n",
    "                classes.append(self.data_mapping[img_path])\n",
    "        return images, np.array(classes)\n",
    "\n",
    "    def get_data_images(self):\n",
    "        t_size = (224,224)\n",
    "        # returns a list of imgpaths and related classes      \n",
    "        images = []\n",
    "        for img_path in self.data_mapping.keys():\n",
    "            if img_path.lower().endswith(('.jpg', '.jpeg')):\n",
    "                img = image.load_img(img_path,target_size=t_size) \n",
    "                img = img_to_array(img)\n",
    "                img = np.asarray(img)\n",
    "                img = color.rgb2gray(img)\n",
    "                #print('arrayImg', img)\n",
    "                images.append(img)\n",
    "        return np.array(images)\n",
    "\n",
    "    def get_data_classes(self, classes_index, label_list):\n",
    "        # returns a list of imgpaths and related classes\n",
    "        classes = []\n",
    "        for img_path in self.data_mapping.keys():\n",
    "            if img_path.lower().endswith(('.jpg', '.jpeg')):\n",
    "                if self.data_mapping[img_path] in label_list:\n",
    "                    classes.append(label_list.index(self.data_mapping[img_path]))\n",
    "                else:\n",
    "                    label_list.append(self.data_mapping[img_path])\n",
    "                    classes.append(classes_index)\n",
    "                    classes_index += 1\n",
    "        print(label_list)\n",
    "        return np.array(classes), classes_index\n",
    "\n",
    "    def num_classes(self):\n",
    "        # returns number of classes of the dataset\n",
    "        return len(self.data_classes)\n",
    "\n",
    "# we define training_path\n",
    "training_path = os.path.join(data_path, 'training')\n",
    "\n",
    "# we define validation path, query and gallery\n",
    "validation_path = os.path.join(data_path, 'validation')\n",
    "gallery_path = os.path.join(validation_path, 'gallery')\n",
    "query_path = os.path.join(validation_path, 'query')\n",
    "\n",
    "\n",
    "training_dataset = Dataset(data_path=training_path)\n",
    "gallery_dataset = Dataset(data_path=gallery_path)\n",
    "query_dataset = Dataset(data_path=query_path)\n",
    "\n",
    "training_paths, training_classes = training_dataset.get_data_paths()\n",
    "\n",
    "# we get validation gallery and query data\n",
    "\n",
    "gallery_paths, gallery_classes = gallery_dataset.get_data_paths()\n",
    "query_paths, query_classes = query_dataset.get_data_paths()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_dataset.get_data_images()\n",
    "y, classes_index = training_dataset.get_data_classes(classes_index, label_list)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "train_images =Xtrain\n",
    "train_labels = ytrain\n",
    "test_images = Xtest\n",
    "test_labels = ytest\n",
    "\n",
    "# Normalize the images.\n",
    "#train_images = (train_images / 255)\n",
    "#test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Reshape the images.\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(train_images[i])\n",
    "    plt.title(int(train_labels[i]))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, 5, activation='relu', padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, 5, activation='relu', padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(keras.layers.Dense(480, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "opt= Adam() # iniziale: 0.001\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  optimizer=opt,\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "epochs = 20\n",
    "with tf.device(\"/gpu:0\"):\n",
    "  history = model.fit(\n",
    "    train_images,\n",
    "    to_categorical(train_labels),\n",
    "    epochs=epochs,\n",
    "    validation_data=(test_images, to_categorical(test_labels)),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=8, verbose=1, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=.5, patience=4, verbose=1)] )\n",
    "  \n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "# Predict on the first 5 test images\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions\n",
    "print(np.argmax(predictions, axis=1))\n",
    "\n",
    "# Check our predictions\n",
    "print(test_labels[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model('/Users/damianoduranti/Desktop/v2.0')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_img = gallery_dataset.get_data_images()\n",
    "gallery_labels, classes_index = gallery_dataset.get_data_classes(classes_index=classes_index, label_list=label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = query_dataset.get_data_images()\n",
    "query_labels, classes_index = query_dataset.get_data_classes(classes_index=classes_index, label_list=label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the first 5 test images.\n",
    "query_prediction = model.predict(query_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(query_prediction))\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_idx = 0\n",
    "distances = []\n",
    "np.set_printoptions(suppress=True)\n",
    "for i in range (len(query_prediction)):\n",
    "    d = 1-spatial.distance.cosine(query_prediction[query_idx], predictions[i])\n",
    "    distances.append([d, i])\n",
    "\n",
    "#print(distances)\n",
    "    \n",
    "distances.sort(reverse=True)    \n",
    "print(\"True class: \"+str(query_labels[query_idx]))\n",
    "print(\"Predicted class: \"+str(gallery_labels[distances[0][1]]))\n",
    "\n",
    "plt.imshow(query_set[80][0].squeeze())\n",
    "plt.title(os.path.dirname(generator1.filenames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(2,5, i + 1)\n",
    "    plt.imshow(gallery_img[distances[i][1]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1 = 0\n",
    "top5 = 0\n",
    "top10 = 0\n",
    "non_top = 0\n",
    "for j in range (len(query_img)):   \n",
    "    distances = []\n",
    "    np.set_printoptions(suppress=True)\n",
    "    for i in range (len(predictions)):\n",
    "        d = 1-spatial.distance.cosine(query_prediction[j], predictions[i])\n",
    "        distances.append([d, i])\n",
    "        \n",
    "    distances.sort(reverse=True)\n",
    "\n",
    "    q_label = int(query_labels[j])\n",
    "    top_ten = distances[:10]\n",
    "    isthere = False\n",
    "    for k in range (len(top_ten)):\n",
    "        if int(gallery_labels[top_ten[k][1]]) == q_label:\n",
    "            isthere = True\n",
    "            if (k+1) == 1:\n",
    "                top1+=1\n",
    "                break\n",
    "            elif (k+1) <=5:\n",
    "                top5+=1\n",
    "                break\n",
    "            elif (k+1) <= 10:\n",
    "                top10+=1\n",
    "                break\n",
    "    if not isthere:\n",
    "        non_top +=1\n",
    "        plt.imshow(query_img[j])\n",
    "        plt.title(int(query_labels[j]))\n",
    "        print(f\"Query number {j} has no top-10 appearences\")\n",
    "        \n",
    "            \n",
    "print(\"top1: \"+ str(top1))\n",
    "print(\"top1: \"+ str(top5))\n",
    "print(\"top1: \"+ str(top10))\n",
    "print(\"Non top: \" + str(non_top))\n",
    "top1 = top1/len(query_img)*100\n",
    "top5 = top5/len(query_img)*100 + top1\n",
    "top10 = top10/len(query_img)*100 + top5\n",
    "print(len(query_img))\n",
    "print(\"top1: \" + str(top1) + \"%\")\n",
    "print(\"top5: \" + str(top5)+ \"%\")\n",
    "print(\"top10: \" + str(top10)+ \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
